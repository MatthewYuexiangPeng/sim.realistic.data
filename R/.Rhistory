Sys.setlocale("LC_ALL", "en_US.UTF-8")
ï¼‰
options("defaultPackages")
Sys.setenv(LANG = "en")
)
rm(list=ls())
library(foreach)
library(doParallel)
source('~/Yuexiang Peng/UW/Research/Jennifer Nelson/Cook/summer project/simu_0817/Final Code/functions.R')
source('D:/OneDrive - UW/Documents/GitHub/sim.realistic.data/R/sim_functions_organized.R')
datdir <- "~/Yuexiang Peng/UW/Research/Jennifer Nelson/Cook/summer project/simu_0817/Data/"
resdir <- "~/Yuexiang Peng/UW/Research/Jennifer Nelson/Cook/summer project/simu_0817/Result/"
# source('G:/CTRHS/Sentinel/Y6_Task_Orders/Methods/Cook-SurvivalII/Programming/Matthew/Final Code/functions_original.R')
# datdir <- "G:/CTRHS/Sentinel/Y7_Task_Orders_2015/Big sim/Data/datatoGHC/datatoGHC/Angioedema/"
# resdir <- '//groups/data/CTRHS/Sentinel/Y6_Task_Orders/Methods/Cook-SurvivalII/Programming/Matthew/Data/'
.ordtonorm <- function (probs, Cor) {
q = length(probs)
categ_probs = 0
cumul_probs = list(0)
quant_probs = list(0)
means = 0
vars = 0
var.wt = function(x, w) {
m = weighted.mean(x = x, w = w)
sum((x[1:length(x)] - m)^2 * w[1:length(x)])
}
for (i in 1:q) {
categ_probs[i] = length(probs[[i]])
cumul_probs[[i]] = cumsum(1:categ_probs[i]/10^12 + probs[[i]])
cumul_probs[[i]][categ_probs[i]] = 1
quant_probs[[i]] = qnorm(p = cumul_probs[[i]], mean = 0,
sd = 1)
means[i] = weighted.mean(x = 1:categ_probs[i], w = probs[[i]])
vars[i] = var.wt(x = 1:categ_probs[i], w = probs[[i]])
}
Cor_norm = Cor
for (i in 1:(q - 1)) {
for (j in (i + 1):q) {
gridd = rep(0, times = 201)
for (ci in 1:(categ_probs[i] - 1)) {
for (cj in 1:(categ_probs[j] - 1)) {
for (steps in -100:100) {
gridd[101 + steps] = gridd[101 + steps] +
mvtnorm::pmvnorm(upper = c(quant_probs[[i]][ci],
quant_probs[[j]][cj]), corr = matrix(2,
2, data = c(1, steps/100, steps/100,
1)))[1]
}
}
}
f = suppressWarnings(approxfun(y = -100:100/100,
x = gridd))
Cor_norm[i, j] = Cor_norm[j, i] = f(Cor[i, j] * sqrt(vars[i] *
vars[j]) + means[i] * means[j] - categ_probs[i] *
categ_probs[j] + categ_probs[j] * sum(cumul_probs[[i]][1:(categ_probs[i] -
1)]) + categ_probs[i] * sum(cumul_probs[[j]][1:(categ_probs[j] -
1)]))
}
}
return(list('corr.norm'=Cor_norm,'quants.norm'=quant_probs))
}
require(survival)
glm_control <- glm.control(epsilon = 1e-8, maxit = 25, trace = FALSE)
cox.ctrl <- survival::coxph.control(eps=1e-09, toler.chol=.Machine$double.eps^0.75,
iter.max=10, toler.inf=sqrt(1e-09), outer.max=10)
sites <- c("AEOS","KPNC","HUOS","HCOS","HPHC")
names(sites) <- rep("site", length(sites))
## Type for censoring time, to fit Weibull model:
#### censtype = "simple", "simplebump", "cov", "covbump"
censtype <- "cov"
# ## Relax cox fitting settings to run faster
# cox.ctrl <- survival::coxph.control(eps=1e-09, toler.chol=.Machine$double.eps^0.75,
#                                     iter.max=20, toler.inf=sqrt(1e-09), outer.max=10)
tie.method <- "efron" ##"exact"
## Maximum follow-up Time (i.e. 1 year = 366 days)
trunc <- 365 # will be used when generating tab1
## Compute proportionate sample sizes using summary stats from full data
Summ.Stat <- readRDS(paste0(resdir,"angio_summary_20160507_cov_chain.rds"))
View(Summ.Stat)
